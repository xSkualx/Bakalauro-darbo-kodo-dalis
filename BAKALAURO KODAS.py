# -*- coding: utf-8 -*-
"""EFPI_ANALIZE_SU_DIAGRAMOMIS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZjTwn5L7Cg3AeJ3Ia1sL1R_yBwRP46Sp

# EFPI Regression and Classification
Comparison using MLP, LSTM, and CNN
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, classification_report
from sklearn.neural_network import MLPRegressor, MLPClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Conv1D, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
from google.colab import files
uploaded = files.upload()

# Funkcija vienerių metų duomenims įkelti ir apjungti
def load_and_merge_year(path, year):
    xls = pd.ExcelFile(path)
    vid = xls.parse("Vidutiniai_metų_duomenys").iloc[3:].reset_index(drop=True)
    klas = xls.parse("Ekologinės_būklės_klasės").iloc[3:].reset_index(drop=True)
    vid.columns = xls.parse("Vidutiniai_metų_duomenys").iloc[2].str.strip()
    klas.columns = xls.parse("Ekologinės_būklės_klasės").iloc[2].str.strip()
    vid.columns = vid.columns.str.strip()
    klas.columns = klas.columns.str.strip()
    df = pd.merge(vid, klas, on=["Regionas", "Monitoringo vietos Nr.", "Vandens telkinio pavadinimas"])
    df["Metai"] = year
    return df


files_order = [
    ("Ežerų fitoplanktonas 2018.xlsx", 2018),
    ("Ežerų fitoplanktonas 2019.xlsx", 2019),
    ("Fitoplanktonas 2020.xlsx", 2020),
    ("2021 m_ ežerų fitoplanktonas.xlsx", 2021),
    ("fitoplanktonas 2022.xlsx", 2022),
    ("Ežerų fitoplanktonas 2023.xlsx", 2023),
]

# Failų sąrašas su metų žymėjimu
dfs = [load_and_merge_year(fname, year) for fname, year in files_order]
train_df = pd.concat(dfs[:-1], ignore_index=True)
df_2023 = dfs[-1]

features = ["Rūšių skaičius, vnt.", "Gausumas, tūkst. vnt./l", "Biomasė, mg/l", "Chlorofilas a, μg/l"]
train_df[features + ["EFPI EKS"]] = train_df[features + ["EFPI EKS"]].apply(pd.to_numeric, errors="coerce")
df_2023[features + ["EFPI EKS"]] = df_2023[features + ["EFPI EKS"]].apply(pd.to_numeric, errors="coerce")

train_df = train_df.dropna(subset=features + ["EFPI EKS", "Ekologinės būklės klasė"])
df_2023 = df_2023.dropna(subset=features + ["EFPI EKS", "Ekologinės būklės klasė"])

# Atrinkti požymiai mokymui (X) ir tikslinė regresijos reikšmė (y)
X_train = train_df[features]
y_train_reg = train_df["EFPI EKS"]
y_train_cls_raw = train_df["Ekologinės būklės klasė"]

X_test = df_2023[features]
y_test_reg = df_2023["EFPI EKS"]
y_test_cls_raw = df_2023["Ekologinės būklės klasė"]

# Duomenų standartizavimas
# Standartizuojame duomenis (vidurkis = 0, std = 1)
scaler = StandardScaler()
# Atrinkti požymiai mokymui (X) ir tikslinė regresijos reikšmė (y)
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Kategorinių kintamųjų kodavimas
# Užkoduojame kategorinius klasifikacijos tikslus į skaitmeninius
label_encoder = LabelEncoder()
# Modelio treniravimas naudojant mokymo duomenis
y_train_cls = label_encoder.fit_transform(y_train_cls_raw)
y_test_cls = label_encoder.transform(y_test_cls_raw)
y_train_cls_cat = to_categorical(y_train_cls)
y_test_cls_cat = to_categorical(y_test_cls)

# Atrinkti požymiai mokymui (X) ir tikslinė regresijos reikšmė (y)
X_train_seq = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
# LSTM ir CNN reikalauja 3D formos įvesties: (pavyzdžių skaičius, laiko žingsniai, požymių skaičius)
X_test_seq = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))

# Papildomų metrikų importavimas
from sklearn.metrics import median_absolute_error, mean_absolute_percentage_error, f1_score

# Naudojame EarlyStopping sustabdyti mokymą, jei nėra pagerėjimo
from tensorflow.keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)

# Pridedame sprendimų medžio ir atsitiktinių miškų modelių bibliotekas
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier

# === REGRESSION ===
# MLP modelis regresijai
mlp_reg = MLPRegressor(hidden_layer_sizes=(10,10), max_iter=1000, random_state=42)
# Modelio treniravimas naudojant mokymo duomenis
mlp_reg.fit(X_train_scaled, y_train_reg)
y_pred_mlp = mlp_reg.predict(X_test_scaled)

# LSTM modelis regresijai
# Sukuriamas modelio karkasas (Sequential API)
lstm_reg = Sequential()
lstm_reg.add(LSTM(64, input_shape=(X_train_seq.shape[1], 1), activation='tanh'))
# Pridedamas tankus sluoksnis (visi neuronai sujungti)
lstm_reg.add(Dense(1))
# Modelio kompiliavimas su pasirinktu optimizatoriumi ir nuostolių funkcija
lstm_reg.compile(optimizer=Adam(0.001), loss='mse')
# Modelio treniravimas naudojant mokymo duomenis
lstm_reg.fit(X_train_seq, y_train_reg, epochs=200, callbacks=[early_stop], batch_size=8, verbose=0)
y_pred_lstm = lstm_reg.predict(X_test_seq).flatten()

# CNN modelis regresijai
# Sukuriamas modelio karkasas (Sequential API)
cnn_reg = Sequential()
cnn_reg.add(Conv1D(32, kernel_size=2, activation='relu', input_shape=(X_train_seq.shape[1], 1)))
cnn_reg.add(Flatten())
# Pridedamas tankus sluoksnis (visi neuronai sujungti)
cnn_reg.add(Dense(64, activation='relu'))
# Pridedamas tankus sluoksnis (visi neuronai sujungti)
cnn_reg.add(Dense(1))
# Modelio kompiliavimas su pasirinktu optimizatoriumi ir nuostolių funkcija
cnn_reg.compile(optimizer=Adam(0.001), loss='mse')
# Modelio treniravimas naudojant mokymo duomenis
cnn_reg.fit(X_train_seq, y_train_reg, epochs=200, callbacks=[early_stop], batch_size=8, verbose=0)
y_pred_cnn = cnn_reg.predict(X_test_seq).flatten()

# === REGRESSION RESULTS ===
print("=== REGRESSION RESULTS ===")
for name, y_pred in zip(["MLP", "LSTM", "CNN"], [y_pred_mlp, y_pred_lstm, y_pred_cnn]):
    mae = mean_absolute_error(y_test_reg, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred))
    r2 = r2_score(y_test_reg, y_pred)
    print(f"{name} -> MAE: {mae:.3f}, RMSE: {rmse:.3f}, R²: {r2:.3f}")

# === CLASSIFICATION ===
# MLP modelis klasifikacijai
mlp_cls = MLPClassifier(hidden_layer_sizes=(10,10), max_iter=1000, random_state=42)
# Modelio treniravimas naudojant mokymo duomenis
mlp_cls.fit(X_train_scaled, y_train_cls)
y_pred_mlp_cls = mlp_cls.predict(X_test_scaled)

# LSTM modelis klasifikacijai
# Sukuriamas modelio karkasas (Sequential API)
lstm_cls = Sequential()
lstm_cls.add(LSTM(64, input_shape=(X_train_seq.shape[1], 1), activation='tanh'))
# Pridedamas tankus sluoksnis (visi neuronai sujungti)
lstm_cls.add(Dense(len(label_encoder.classes_), activation='softmax'))
# Modelio kompiliavimas su pasirinktu optimizatoriumi ir nuostolių funkcija
lstm_cls.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])
# Modelio treniravimas naudojant mokymo duomenis
lstm_cls.fit(X_train_seq, y_train_cls_cat, epochs=200, callbacks=[early_stop], batch_size=8, verbose=0)
y_pred_lstm_cls = lstm_cls.predict(X_test_seq).argmax(axis=1)

# CNN modelis klasifikacijai
# Sukuriamas modelio karkasas (Sequential API)
cnn_cls = Sequential()
cnn_cls.add(Conv1D(32, kernel_size=2, activation='relu', input_shape=(X_train_seq.shape[1], 1)))
cnn_cls.add(Flatten())
# Pridedamas tankus sluoksnis (visi neuronai sujungti)
cnn_cls.add(Dense(64, activation='relu'))
# Pridedamas tankus sluoksnis (visi neuronai sujungti)
cnn_cls.add(Dense(len(label_encoder.classes_), activation='softmax'))
# Modelio kompiliavimas su pasirinktu optimizatoriumi ir nuostolių funkcija
cnn_cls.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])
# Modelio treniravimas naudojant mokymo duomenis
cnn_cls.fit(X_train_seq, y_train_cls_cat, epochs=200, callbacks=[early_stop], batch_size=8, verbose=0)
y_pred_cnn_cls = cnn_cls.predict(X_test_seq).argmax(axis=1)

# === CLASSIFICATION RESULTS ===
print("\n=== CLASSIFICATION RESULTS ===")
# LSTM modelis klasifikacijai
for name, y_pred in zip(["MLP", "LSTM", "CNN"], [y_pred_mlp_cls, y_pred_lstm_cls, y_pred_cnn_cls]):
    acc = accuracy_score(y_test_cls, y_pred)
    print(f"{name} -> Tikslumas: {acc:.3f}")
# Klasifikacijos ataskaita
    print(classification_report(y_test_cls, y_pred, target_names=label_encoder.classes_))

plt.figure(figsize=(12, 6))
# Grafikas: tikros ir prognozuotos EFPI reikšmės
plt.plot(y_test_reg.values, label="Tikroji EFPI", marker='o')
# Grafikas: tikros ir prognozuotos EFPI reikšmės
plt.plot(y_pred_mlp, label="MLP prognozė", marker='x')
# Grafikas: tikros ir prognozuotos EFPI reikšmės
plt.plot(y_pred_lstm, label="LSTM prognozė", marker='s')
# Grafikas: tikros ir prognozuotos EFPI reikšmės
plt.plot(y_pred_cnn, label="CNN prognozė", marker='^')
plt.legend()
plt.title("EFPI prognozės: MLP vs LSTM vs CNN")
plt.xlabel("Vandens telkinių stebėjimo taškai")
plt.ylabel("EFPI tikslumas")
plt.grid(True)
plt.show()

# Painiavos matricos sudarymas ir atvaizdavimas visiems klasifikatoriams

# === Painiavos matricos (confusion matrices) vizualizavimas ===
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

model_names = ["MLP", "LSTM", "CNN"]
predictions = [y_pred_mlp_cls, y_pred_lstm_cls, y_pred_cnn_cls]

for name, y_pred in zip(model_names, predictions):
    cm = confusion_matrix(y_test_cls, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)
    disp.plot(cmap="Blues")
    plt.title(f"{name} klasifikavimo lentelė")
    plt.grid(False)
    plt.show()

# Papildomų regresijos metrikų skaičiavimas (MAPE ir MedAE)
for name, y_pred in zip(["MLP", "LSTM", "CNN"], [y_pred_mlp, y_pred_lstm, y_pred_cnn]):
    mae = mean_absolute_error(y_test_reg, y_pred)  # Vidutinė absoliuti klaida
    rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred))  # Šakninis vid. kv. nuokrypis
    r2 = r2_score(y_test_reg, y_pred)  # Determinacijos koeficientas
    medae = median_absolute_error(y_test_reg, y_pred)  # Medianinė klaida
    mape = mean_absolute_percentage_error(y_test_reg, y_pred) * 100  # Vidutinė klaida procentais
    print(f"{name} -> MAE: {mae:.3f}, RMSE: {rmse:.3f}, R²: {r2:.3f}, MedAE: {medae:.3f}, MAPE: {mape:.2f}%")

# Klasifikacijos metrikų (F1-weighted) skaičiavimas
for name, y_pred in zip(["MLP", "LSTM", "CNN"], [y_pred_mlp_cls, y_pred_lstm_cls, y_pred_cnn_cls]):
    acc = accuracy_score(y_test_cls, y_pred)  # Tikslumas (Accuracy)
    f1_weighted = f1_score(y_test_cls, y_pred, average='weighted')  # Svertinis F1-score
    print(f"{name} -> Tikslumas: {acc:.3f}, F1-svertinis: {f1_weighted:.3f}")
    print(classification_report(y_test_cls, y_pred, target_names=label_encoder.classes_))

# Sklaidos diagramos visiems regresijos modeliams
models = ["MLP", "LSTM", "CNN"]
predictions = [y_pred_mlp, y_pred_lstm, y_pred_cnn]

for name, y_pred in zip(models, predictions):
    plt.figure(figsize=(6,6))
    plt.scatter(y_test_reg, y_pred, alpha=0.7)
    plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--')
    plt.xlabel("Tikroji EFPI")
    plt.ylabel(f"Prognozuota EFPI ({name})")
    plt.title(f"{name} regresijos sklaidos diagrama")
    plt.grid(True)
    plt.show()

# === Sprendimų medis ir Atsitiktiniai miškai: regresija ===

# Mokome sprendimų medį
tree_reg = DecisionTreeRegressor(random_state=42)
tree_reg.fit(X_train_scaled, y_train_reg)
y_pred_tree = tree_reg.predict(X_test_scaled)

# Mokome atsitiktinių miškų modelį
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train_scaled, y_train_reg)
y_pred_rf = rf_reg.predict(X_test_scaled)

# Spausdiname metrikas
print("=== REGRESIJA: Sprendimų medis ir Atsitiktiniai miškai ===")
for name, y_pred in zip(["Decision Tree", "Random Forest"], [y_pred_tree, y_pred_rf]):
    mae = mean_absolute_error(y_test_reg, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred))
    r2 = r2_score(y_test_reg, y_pred)
    medae = median_absolute_error(y_test_reg, y_pred)
    mape = mean_absolute_percentage_error(y_test_reg, y_pred) * 100
    print(f"{name} -> MAE: {mae:.3f}, RMSE: {rmse:.3f}, R²: {r2:.3f}, MedAE: {medae:.3f}, MAPE: {mape:.2f}%")

# === Sprendimų medis ir Atsitiktiniai miškai: klasifikacija ===

# Mokome sprendimų medį klasifikacijai
tree_cls = DecisionTreeClassifier(random_state=42)
tree_cls.fit(X_train_scaled, y_train_cls)
y_pred_tree_cls = tree_cls.predict(X_test_scaled)

# Mokome atsitiktinius miškus klasifikacijai
rf_cls = RandomForestClassifier(n_estimators=100, random_state=42)
rf_cls.fit(X_train_scaled, y_train_cls)
y_pred_rf_cls = rf_cls.predict(X_test_scaled)

# Spausdiname metrikas
print("\n=== KLASIFIKACIJA: Sprendimų medis ir Atsitiktiniai miškai ===")
for name, y_pred in zip(["Decision Tree", "Random Forest"], [y_pred_tree_cls, y_pred_rf_cls]):
    acc = accuracy_score(y_test_cls, y_pred)
    f1_weighted = f1_score(y_test_cls, y_pred, average='weighted')
    print(f"{name} -> Tikslumas: {acc:.3f}, F1-svertinis: {f1_weighted:.3f}")
    print(classification_report(y_test_cls, y_pred, target_names=label_encoder.classes_))

# Painiavos matricos: Sprendimų medis ir Atsitiktiniai miškai
for name, y_pred in zip(["Decision Tree", "Random Forest"], [y_pred_tree_cls, y_pred_rf_cls]):
    cm = confusion_matrix(y_test_cls, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)
    disp.plot(cmap="Blues")
    plt.title(f"{name} klasifikavimo lentelė")
    plt.grid(False)
    plt.show()

# Sklaidos diagramos: Decision Tree ir Random Forest (regresija)
for name, y_pred in zip(["Decision Tree", "Random Forest"], [y_pred_tree, y_pred_rf]):
    plt.figure(figsize=(6,6))
    plt.scatter(y_test_reg, y_pred, alpha=0.7)
    plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--')
    plt.xlabel("Tikroji EFPI")
    plt.ylabel(f"Prognozuota EFPI ({name})")
    plt.title(f"{name} regresijos sklaidos diagrama")
    plt.grid(True)
    plt.show()